{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGTMENK5jomSHeZMVW3YCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junho2000/pytorch-practice/blob/main/pytorch_%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor 다루기"
      ],
      "metadata": {
        "id": "-ISw2OS-zJP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRCwBIdN8aQ_",
        "outputId": "9ca4c5f2-0913-4571-cbfa-3466273c86e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5],\n",
              "        [6, 7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nums = torch.arange(9)\n",
        "nums.numpy()\n",
        "nums.reshape(3,3)\n",
        "\n",
        "# nums = torch.arange(9).reshape(3, 3)\n",
        "# nums"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1,2],[3,4]])\n",
        "torch.tensor([[1,2],[3,4.]], device=\"cuda:0\") #use gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkwheI9S8si8",
        "outputId": "73dc85f9-9855-4929-e0b9-e2d48be7b61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1,2],[3,4]],dtype=torch.float64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpE4V_NH9PPL",
        "outputId": "e07769a8-ad78-400e-aa70-da8526c68003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(0,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z3s2syB9-o_",
        "outputId": "8c353469-b920-4aa1-c477-8f58cfb51600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(3,5).to('cuda:0') #use gpu\n",
        "#to('cuda:0') / device=\"cuda:0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJirvQX7-CxQ",
        "outputId": "0c3b2086-dcf4-4078-aba1-990764f678b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.randn(3, 5)\n",
        "t.size()\n",
        "#t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOMY1_3Q-IWC",
        "outputId": "e69d9438-8766-495e-b02a-9673b1780f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.linspace(0, 10, 100)\n",
        "y = torch.exp(x)\n",
        "\n",
        "plt.plot(x.numpy(), y.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "J_t7-PvTCVyp",
        "outputId": "e507531d-eb7e-42d9-e921-a8613bcfa234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcd81ab7a50>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1,2,3],[4,5,6.]])\n",
        "print(t[0,2])\n",
        "print(t[:,:2])\n",
        "t[t > 3] = 10\n",
        "#t[:, 1] = 10\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP0bwGyuCgKv",
        "outputId": "ab6baf8d-120a-43be-ef44-c1c796bd3843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.)\n",
            "tensor([[1., 2.],\n",
            "        [4., 5.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  2.,  3.],\n",
              "        [10., 10., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([1,2,3.])\n",
        "w = torch.tensor([0, 10, 20])\n",
        "\n",
        "m = torch.tensor([[0, 1, 2], [100, 200, 300.]])\n",
        "\n",
        "m2 = m + m\n",
        "\n",
        "m2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04XNEHCiCsKb",
        "outputId": "ca7e0160-38fa-49b8-bf6c-148ac4dc1c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,   2.,   4.],\n",
              "        [200., 400., 600.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor dimension control\n",
        "\n",
        "x1 = torch.tensor([\n",
        "    [1, 2], [3, 4.]\n",
        "])\n",
        "\n",
        "x2 = torch.tensor([\n",
        "    [10, 20, 30], [40, 50, 60.]\n",
        "])\n",
        "\n",
        "#x1.view(4,1)\n",
        "x1.reshape(4,1)\n",
        "\n",
        "x1.view(-1)\n",
        "#x1.reshape(-1)\n",
        "\n",
        "#x1.view(-1,1)\n",
        "x1.reshape(-1,1)\n",
        "\n",
        "print(x2.t()) #transpose\n",
        "\n",
        "print(torch.cat([x1,x2], dim=1))\n",
        "\n",
        "hwc_img_data = torch.rand(100, 64, 32, 3)\n",
        "chw_img_data = hwc_img_data.transpose(1,2).transpose(1,3)\n",
        "chw_img_data.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruRJ7yLfDe_y",
        "outputId": "26b42427-7c8b-4722-f420-23a0d9ff51f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10., 40.],\n",
            "        [20., 50.],\n",
            "        [30., 60.]])\n",
            "tensor([[ 1.,  2., 10., 20., 30.],\n",
            "        [ 3.,  4., 40., 50., 60.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 3, 64, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.torch.randperm(5)\n",
        "torch.arange(0,3,step=0.5) #torch.arange(시작, 끝, step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwilsLMAEMT2",
        "outputId": "b5140d94-dc5c-4798-e197-d7cad53d7848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.FloatTensor([2,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN6PVKlzFZ32",
        "outputId": "91db5a97-eccc-4109-ad92-bb404a1d228b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.cuda.FloatTensor([2,3])\n",
        "x.type_as(torch.cuda.IntTensor()) #type change in cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faSPJ3ZYFru9",
        "outputId": "1a5678d6-dea8-458f-ac2c-657e480bf8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3], device='cuda:0', dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.ndarray(shape=(2,3), dtype=int, buffer=np.array([1,2,3,4,5,6]))\n",
        "\n",
        "x = torch.from_numpy(x1)\n",
        "\n",
        "x2 = torch.from_numpy(x1)\n",
        "print(x2.numpy())\n",
        "print(x2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cahSYl_WGBL4",
        "outputId": "db202a83-0855-443e-ea9d-c755cf3cd6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
        "x_gpu = x.cuda()\n",
        "print(x_gpu)\n",
        "\n",
        "x_cpu = x_gpu.cpu()\n",
        "print(x_cpu)\n",
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC_C5ScVHcI-",
        "outputId": "759528fc-3261-43ee-a909-800c387927df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], device='cuda:0')\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4,3)\n",
        "print(x)\n",
        "print(torch.index_select(x,0,torch.tensor([0,2])))\n",
        "#input, dim, index\n",
        "\n",
        "#torch.LongTensor([0,2])\n",
        "#torch.tensor([0,2])\n",
        "\n",
        "print(x[:,0].view(-1,1))\n",
        "print(x[0,:])\n",
        "\n",
        "x[0:2,0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1QXaqplH7hL",
        "outputId": "fb00c39c-9471-4e8c-8397-38707af6885d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5521, 0.9945, 0.4801],\n",
            "        [0.2009, 0.7143, 0.3598],\n",
            "        [0.7185, 0.0875, 0.3665],\n",
            "        [0.5672, 0.2711, 0.7601]])\n",
            "tensor([[0.5521, 0.9945, 0.4801],\n",
            "        [0.7185, 0.0875, 0.3665]])\n",
            "tensor([[0.5521],\n",
            "        [0.2009],\n",
            "        [0.7185],\n",
            "        [0.5672]])\n",
            "tensor([0.5521, 0.9945, 0.4801])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5521, 0.9945],\n",
              "        [0.2009, 0.7143]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,3)\n",
        "print(x)\n",
        "mask = torch.BoolTensor([[0,0,1],[0,1,0]])\n",
        "print(mask)\n",
        "torch.masked_select(x,mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv5901JDIgD5",
        "outputId": "c0490e2a-3ebc-4e3b-954c-21373df4eda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8362,  1.1323, -0.9856],\n",
            "        [-0.5889,  0.7317,  1.1745]])\n",
            "tensor([[False, False,  True],\n",
            "        [False,  True, False]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9856,  0.7317])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.cuda.FloatTensor([[1, 2, 3], [4, 5, 6]])\n",
        "y = torch.cuda.FloatTensor([[-1, -2, -3], [-4, -5, -6]])\n",
        "z1 = torch.cat([x, y], dim=0)\n",
        "print(z1)\n",
        "z2 = torch.cat([x, y], dim=1)\n",
        "print(z2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFi4lB0aJjIo",
        "outputId": "4a42c764-0a53-43b5-f279-063e1cb12727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.],\n",
            "        [-1., -2., -3.],\n",
            "        [-4., -5., -6.]], device='cuda:0')\n",
            "tensor([[ 1.,  2.,  3., -1., -2., -3.],\n",
            "        [ 4.,  5.,  6., -4., -5., -6.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
        "print(x)\n",
        "x_stack0 = torch.stack([x,x,x,x],dim=0)\n",
        "x_stack1 = torch.stack([x,x,x,x],dim=1)\n",
        "\n",
        "print(x_stack0.shape)\n",
        "print(x_stack1.shape)\n",
        "\n",
        "print(x_stack0)\n",
        "print(x_stack1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH-mknbMK01H",
        "outputId": "268d5960-35dc-4f71-cd9a-495ecd981ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([4, 2, 3])\n",
            "torch.Size([2, 4, 3])\n",
            "tensor([[[1., 2., 3.],\n",
            "         [4., 5., 6.]],\n",
            "\n",
            "        [[1., 2., 3.],\n",
            "         [4., 5., 6.]],\n",
            "\n",
            "        [[1., 2., 3.],\n",
            "         [4., 5., 6.]],\n",
            "\n",
            "        [[1., 2., 3.],\n",
            "         [4., 5., 6.]]])\n",
            "tensor([[[1., 2., 3.],\n",
            "         [1., 2., 3.],\n",
            "         [1., 2., 3.],\n",
            "         [1., 2., 3.]],\n",
            "\n",
            "        [[4., 5., 6.],\n",
            "         [4., 5., 6.],\n",
            "         [4., 5., 6.],\n",
            "         [4., 5., 6.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor를 몇개의 부분으로 나뉘는 기능\n",
        "x_1, x_2 = torch.chunk(z1,2,dim=0)\n",
        "y_1, y_2, y_3 = torch.chunk(z1,3,dim=1)\n",
        "\n",
        "print(z1)\n",
        "\n",
        "\n",
        "print(x_1)\n",
        "print(x_2)\n",
        "print(y_1)\n",
        "print(y_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ5-Gm_YK-vx",
        "outputId": "ab0df8d2-e003-4319-9941-cbac8e071b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.],\n",
            "        [-1., -2., -3.],\n",
            "        [-4., -5., -6.]], device='cuda:0')\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], device='cuda:0')\n",
            "tensor([[-1., -2., -3.],\n",
            "        [-4., -5., -6.]], device='cuda:0')\n",
            "tensor([[ 1.],\n",
            "        [ 4.],\n",
            "        [-1.],\n",
            "        [-4.]], device='cuda:0')\n",
            "tensor([[ 2.],\n",
            "        [ 5.],\n",
            "        [-2.],\n",
            "        [-5.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 1, 2, 1, 2)\n",
        "print(x.size())\n",
        "\n",
        "y = torch.squeeze(x)\n",
        "print(y.size())\n",
        "\n",
        "y = torch.squeeze(x, 0) #torch.squeeze(input, dim)\n",
        "print(y.size())\n",
        "\n",
        "y = torch.squeeze(x, 1)\n",
        "print(y.size())\n",
        "\n",
        "A = torch.arange(1, 10)\n",
        "indices = torch.tensor([0, 3, 5, 6])\n",
        "print(torch.gather(A, 0, indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoL_WPZqNq9N",
        "outputId": "c9188b1d-816d-4d01-cd3b-32cf886d8655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 2, 1, 2])\n",
            "torch.Size([2, 2, 2])\n",
            "torch.Size([2, 1, 2, 1, 2])\n",
            "torch.Size([2, 2, 1, 2])\n",
            "tensor([1, 4, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2,3,4)\n",
        "x = torch.unsqueeze(x, 0) #(input, dim)\n",
        "print(x.shape)\n",
        "\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(x.shape)\n",
        "\n",
        "x = torch.unsqueeze(x, 1)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5BFY3SnPJWH",
        "outputId": "6679cf2c-bd65-4674-e4aa-2f8c13475e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 3, 4])\n",
            "torch.Size([4])\n",
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#init, uniform함수를 사용하면 uniform 또는 normal 분포의 초기화 Tensor\n",
        "import torch.nn.init as init\n",
        "\n",
        "x1 = init.uniform(torch.FloatTensor(3,4),a=0,b=9) # 0 ~ 9\n",
        "print(x1)\n",
        "\n",
        "x2 = init.normal(torch.FloatTensor(3,4),std=0.2)\n",
        "print(x2)\n",
        "\n",
        "x3 = init.constant(torch.FloatTensor(3,4),3.1415)\n",
        "print(x3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7grwedfNPJTy",
        "outputId": "24104211-f66f-4619-c882-ad6d6a78ce00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.0938e+00, 2.2173e+00, 7.3982e+00, 1.3245e+00],\n",
            "        [3.8172e+00, 1.7512e+00, 1.8866e-01, 6.5503e-01],\n",
            "        [6.9655e+00, 7.3300e+00, 5.1337e-04, 2.9836e+00]])\n",
            "tensor([[-0.0920,  0.0016, -0.0051, -0.0881],\n",
            "        [ 0.0300,  0.1175, -0.0416, -0.1044],\n",
            "        [-0.4201, -0.0064, -0.0689,  0.5081]])\n",
            "tensor([[3.1415, 3.1415, 3.1415, 3.1415],\n",
            "        [3.1415, 3.1415, 3.1415, 3.1415],\n",
            "        [3.1415, 3.1415, 3.1415, 3.1415]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix multiplication\n",
        "a = torch.tensor([1,2,3,4,5,6]).view(3,2)\n",
        "b = torch.tensor([9,8,7,6,5,4]).view(2,3)\n",
        "#ab = torch.matmul(a,b) / torch.mm(a,b)\n",
        "ab = a@b\n",
        "print(ab)\n",
        "\n",
        "x1 = torch.FloatTensor(3,4)\n",
        "x2 = torch.FloatTensor(4,5)\n",
        "torch.mm(x1,x2).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL98HwNuPJRd",
        "outputId": "ef4e2752-b15a-409f-e69e-19488b07f1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[21, 18, 15],\n",
            "        [51, 44, 37],\n",
            "        [81, 70, 59]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
        "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
        "add = x1 + x2\n",
        "add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV7-GowvPJO0",
        "outputId": "b24456b3-2c24-45d2-8e24-6e3e76be34f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  4.,  6.],\n",
              "        [ 8., 10., 12.]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
        "x1+10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLtCyVWIPJMg",
        "outputId": "14eb2613-4f1c-4c42-8ecf-409c44e4c4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 12., 13.],\n",
              "        [14., 15., 16.]])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
        "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
        "print(x1*x2) #요소끼리 곱\n",
        "print(x1/x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNo3PdrtR6Be",
        "outputId": "5dfbef74-8a3f-4f53-87cb-58042fea42b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  4.,  9.],\n",
            "        [16., 25., 36.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.FloatTensor([ [1,2,3], [4,5,6] ])\n",
        "torch.exp(x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFMPnukhR97g",
        "outputId": "bea099ef-63fd-4902-f96a-f1651b334777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2.7183,   7.3891,  20.0855],\n",
              "        [ 54.5981, 148.4132, 403.4288]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.ones(5, 3, 3)\n",
        "print(\"A.shape : \", A.shape)\n",
        "\n",
        "v = torch.arange(0, 5)\n",
        "print(\"v.shape : \", v.shape)\n",
        "\n",
        "v_tensor = v.view(v.size()[0], 1, 1)\n",
        "print(\"v_tensor.shape : \", v_tensor.shape)\n",
        "\n",
        "result = v_tensor * A #(5,3,3) and (5,1,1) multiplication 요소끼리\n",
        "print(\"result.shape : \", result.shape)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeomMezLSTub",
        "outputId": "78eb85f0-5a0a-4959-8463-3066a20bd13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A.shape :  torch.Size([5, 3, 3])\n",
            "v.shape :  torch.Size([5])\n",
            "v_tensor.shape :  torch.Size([5, 1, 1])\n",
            "result.shape :  torch.Size([5, 3, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[2., 2., 2.],\n",
            "         [2., 2., 2.],\n",
            "         [2., 2., 2.]],\n",
            "\n",
            "        [[3., 3., 3.],\n",
            "         [3., 3., 3.],\n",
            "         [3., 3., 3.]],\n",
            "\n",
            "        [[4., 4., 4.],\n",
            "         [4., 4., 4.],\n",
            "         [4., 4., 4.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.gather 함수는 tensor에서 인덱스를 기준으로 특정 값들을 추출하기 위해 사용\n",
        "A = torch.arange(1, 10)\n",
        "indices = torch.tensor([0, 3, 5, 6])\n",
        "print(A)\n",
        "print(torch.gather(A, 0, indices)) #tensor, dimension, tensor.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuV78KhNS7Co",
        "outputId": "731e2590-e8ca-4144-de4b-706676604299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([1, 4, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(25).reshape(5, 5)\n",
        "indices = torch.tensor([\n",
        "    [0, 1, 2],\n",
        "    [1, 2, 3],\n",
        "    [2, 3, 3],\n",
        "    [3, 4, 1],\n",
        "    [0, 0, 0]])\n",
        "print(A)\n",
        "print(torch.gather(A, 0, indices)) #indices의 shape과 같음, dim = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3SfsFzSf4e7",
        "outputId": "07f44b89-7673-4ff6-9231-e7fd13e517c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19],\n",
            "        [20, 21, 22, 23, 24]])\n",
            "tensor([[ 0,  6, 12],\n",
            "        [ 5, 11, 17],\n",
            "        [10, 16, 17],\n",
            "        [15, 21,  7],\n",
            "        [ 0,  1,  2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(27).reshape(3, 3, 3)\n",
        "indices = torch.tensor([\n",
        "    [[0,0,0],[1,1,1],[2,2,2]],\n",
        "    [[1,1,1],[2,2,2,],[0,0,0]],\n",
        "    [[0,1,2],[0,1,2],[0,1,2]]])\n",
        "\n",
        "print(A)\n",
        "print(indices)\n",
        "torch.gather(A, 2, indices) #dim = 2, -->"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxh6bZDVglJI",
        "outputId": "3f975ce6-54fe-4b8f-a2cf-6b99b5568067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5],\n",
            "         [ 6,  7,  8]],\n",
            "\n",
            "        [[ 9, 10, 11],\n",
            "         [12, 13, 14],\n",
            "         [15, 16, 17]],\n",
            "\n",
            "        [[18, 19, 20],\n",
            "         [21, 22, 23],\n",
            "         [24, 25, 26]]])\n",
            "tensor([[[0, 0, 0],\n",
            "         [1, 1, 1],\n",
            "         [2, 2, 2]],\n",
            "\n",
            "        [[1, 1, 1],\n",
            "         [2, 2, 2],\n",
            "         [0, 0, 0]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [0, 1, 2],\n",
            "         [0, 1, 2]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  0,  0],\n",
              "         [ 4,  4,  4],\n",
              "         [ 8,  8,  8]],\n",
              "\n",
              "        [[10, 10, 10],\n",
              "         [14, 14, 14],\n",
              "         [15, 15, 15]],\n",
              "\n",
              "        [[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#expand는 특정 텐서를 반복하여 생성하며 개수가 1인 차원에만 적용하여 반복\n",
        "x = torch.tensor([[1], [2], [3]])\n",
        "print(x.size())\n",
        "print(x)\n",
        "x.expand(3,4)\n",
        "x.expand(-1,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYxyB29XiXxx",
        "outputId": "85c56aef-8079-44c5-8e13-d161811c3d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1],\n",
              "        [2, 2, 2, 2],\n",
              "        [3, 3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.rand(3, 1, 1)\n",
        "print(y)\n",
        "y.expand(-1, 3, 4) #3x3x4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il602nBLlvbc",
        "outputId": "09710c45-c425-47d2-b03d-a6d09ad935cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.6900]],\n",
            "\n",
            "        [[0.7268]],\n",
            "\n",
            "        [[0.0450]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.6900, 0.6900, 0.6900, 0.6900],\n",
              "         [0.6900, 0.6900, 0.6900, 0.6900],\n",
              "         [0.6900, 0.6900, 0.6900, 0.6900]],\n",
              "\n",
              "        [[0.7268, 0.7268, 0.7268, 0.7268],\n",
              "         [0.7268, 0.7268, 0.7268, 0.7268],\n",
              "         [0.7268, 0.7268, 0.7268, 0.7268]],\n",
              "\n",
              "        [[0.0450, 0.0450, 0.0450, 0.0450],\n",
              "         [0.0450, 0.0450, 0.0450, 0.0450],\n",
              "         [0.0450, 0.0450, 0.0450, 0.0450]]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 3) \n",
        "print(x.repeat(3, 2, 2)) #channel, row x 2, colum x 2\n",
        "x.repeat(3, 2, 2).shape #3,2x2,2x2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy9VOFOBmG5n",
        "outputId": "345e8052-f2db-4131-da4d-941349b95298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9280, 0.0224, 0.1585, 0.9280, 0.0224, 0.1585],\n",
            "         [0.9749, 0.6852, 0.8526, 0.9749, 0.6852, 0.8526],\n",
            "         [0.9280, 0.0224, 0.1585, 0.9280, 0.0224, 0.1585],\n",
            "         [0.9749, 0.6852, 0.8526, 0.9749, 0.6852, 0.8526]],\n",
            "\n",
            "        [[0.9280, 0.0224, 0.1585, 0.9280, 0.0224, 0.1585],\n",
            "         [0.9749, 0.6852, 0.8526, 0.9749, 0.6852, 0.8526],\n",
            "         [0.9280, 0.0224, 0.1585, 0.9280, 0.0224, 0.1585],\n",
            "         [0.9749, 0.6852, 0.8526, 0.9749, 0.6852, 0.8526]],\n",
            "\n",
            "        [[0.9280, 0.0224, 0.1585, 0.9280, 0.0224, 0.1585],\n",
            "         [0.9749, 0.6852, 0.8526, 0.9749, 0.6852, 0.8526],\n",
            "         [0.9280, 0.0224, 0.1585, 0.9280, 0.0224, 0.1585],\n",
            "         [0.9749, 0.6852, 0.8526, 0.9749, 0.6852, 0.8526]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.rand(2, 3, 2)\n",
        "y.repeat(3, 4, 5, 6).shape #3x1, 4x2, 5x3, 6x2\n",
        "#expand의 경우 원본 tensor를 참조하여 만들기 때문에 \n",
        "#원본 tensor의 값이 변경이 되면 expand의 값 또한 변경됩니다. \n",
        "#반면 repeat은 깊은 복사로 만들어지기 때문에 원본 tensor가 변경되더라도 \n",
        "# 값 변경이 발생하지 않습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anidIcFYoD_q",
        "outputId": "feef6586-323c-4f4d-8900-7285f1f49a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 8, 15, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1., 6.)\n",
        "values, indices = torch.topk(x, 3) #return value, index\n",
        "print(x)\n",
        "print(values)\n",
        "print(indices)\n",
        "#입력받은 텐서 x의 dimension 별 가장 큰 3개의 값과 그 위치를 추출하는 것입니다. \n",
        "#dimension은 3번째 인자이고 따로 입력하지 않은 경우 \n",
        "#마지막 dimension을 사용하게 됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzHxZ4C_owNK",
        "outputId": "e565c574-3985-4ff5-8903-71e9e2e8e400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5.])\n",
            "tensor([5., 4., 3.])\n",
            "tensor([4, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 4, 3)\n",
        "values, indices = torch.topk(x, 2) #dim = 2\n",
        "print(x)\n",
        "print(values)\n",
        "print(indices)\n",
        "print(indices.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic91rvPFq0NO",
        "outputId": "a6654e19-1c9d-4e24-8452-38e9a30d4836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.7702, 0.4392, 0.1186],\n",
            "         [0.5032, 0.7453, 0.6206],\n",
            "         [0.5413, 0.5538, 0.5769],\n",
            "         [0.0592, 0.5148, 0.0655]],\n",
            "\n",
            "        [[0.7041, 0.1461, 0.2755],\n",
            "         [0.3789, 0.2761, 0.1558],\n",
            "         [0.3540, 0.9210, 0.4165],\n",
            "         [0.8168, 0.0528, 0.3268]]])\n",
            "tensor([[[0.7702, 0.4392],\n",
            "         [0.7453, 0.6206],\n",
            "         [0.5769, 0.5538],\n",
            "         [0.5148, 0.0655]],\n",
            "\n",
            "        [[0.7041, 0.2755],\n",
            "         [0.3789, 0.2761],\n",
            "         [0.9210, 0.4165],\n",
            "         [0.8168, 0.3268]]])\n",
            "tensor([[[0, 1],\n",
            "         [1, 2],\n",
            "         [2, 1],\n",
            "         [1, 2]],\n",
            "\n",
            "        [[0, 2],\n",
            "         [0, 1],\n",
            "         [1, 2],\n",
            "         [0, 2]]])\n",
            "torch.Size([2, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.gather와 topk를 이용하여 특정 차원을 기준으로 topk 개의 값을 추출\n",
        "values, indices = torch.topk(x, 2, dim=1) #x에서 2개 차원1\n",
        "print(x)\n",
        "print(values)\n",
        "print(indices)\n",
        "torch.gather(x, 1, indices) == values #최대값들을 찾을을 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_VPti8jrcYb",
        "outputId": "c7942ea4-d2d0-4b7c-a937-3f7266e9db58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1467, 0.1845, 0.6555],\n",
            "         [0.6265, 0.4187, 0.8788],\n",
            "         [0.1532, 0.6673, 0.7262],\n",
            "         [0.2282, 0.2324, 0.6550]],\n",
            "\n",
            "        [[0.0117, 0.9834, 0.4113],\n",
            "         [0.7417, 0.7208, 0.8819],\n",
            "         [0.8603, 0.8344, 0.2857],\n",
            "         [0.2930, 0.2195, 0.9882]]])\n",
            "tensor([[[0.6265, 0.6673, 0.8788],\n",
            "         [0.2282, 0.4187, 0.7262]],\n",
            "\n",
            "        [[0.8603, 0.9834, 0.9882],\n",
            "         [0.7417, 0.8344, 0.8819]]])\n",
            "tensor([[[1, 2, 1],\n",
            "         [3, 1, 2]],\n",
            "\n",
            "        [[2, 0, 3],\n",
            "         [1, 2, 1]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[True, True, True],\n",
              "         [True, True, True]],\n",
              "\n",
              "        [[True, True, True],\n",
              "         [True, True, True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 4, 5)\n",
        "y = torch.rand(3, 4, 5)\n",
        "\n",
        "# x의 2번째 차원을 기준으로 가장 큰 값을 하나 뽑습니다.\n",
        "values, indices = torch.topk(x, 1, dim=2)\n",
        "# x에서 추출된 값과 똑같은 위치에서 y의 값을 하나 뽑습니다.\n",
        "torch.gather(y, 2, indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VmnhwUArza8",
        "outputId": "a1d12f24-74b5-4d06-80cb-8a471884320f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3351],\n",
              "         [0.7521],\n",
              "         [0.1319],\n",
              "         [0.7200]],\n",
              "\n",
              "        [[0.4556],\n",
              "         [0.2345],\n",
              "         [0.6143],\n",
              "         [0.7708]],\n",
              "\n",
              "        [[0.1799],\n",
              "         [0.8642],\n",
              "         [0.5701],\n",
              "         [0.8447]]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn # neural network 모음. (e.g. nn.Linear, nn.Conv2d, BatchNorm, Loss functions 등등)\n",
        "import torch.optim as optim # Optimization algorithm 모음, (e.g. SGD, Adam, 등등)\n",
        "import torch.nn.functional as F # 파라미터가 필요없는 Function 모음\n",
        "from torch.utils.data import DataLoader # 데이터 세트 관리 및 미니 배치 생성을 위한 함수 모음\n",
        "import torchvision.datasets as datasets # 표준 데이터 세트 모음\n",
        "import torchvision.transforms as transforms # 데이터 세트에 적용 할 수있는 변환 관련 함수 모음\n",
        "from torch.utils.tensorboard import SummaryWriter # tensorboard에 출력하기 위한 함수 모음\n",
        "import torch.backends.cudnn as cudnn # cudnn을 다루기 위한 값 모음\n",
        "\n",
        "from torchsummary import summary # summary를 통한 model의 현황을 확인 하기 위함\n",
        "import torch.onnx # model을 onnx 로 변환하기 위함"
      ],
      "metadata": {
        "id": "OouCwGOTsm9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cuda가 사용 가능한 지 확인\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# cuda가 사용 가능하면 device에 \"cuda\"를 저장하고 사용 가능하지 않으면 \"cpu\"를 저장한다.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 멀티 GPU 사용 시 사용 가능한 GPU 셋팅 관련\n",
        "# 아래 코드의 \"0,1,2\"는 GPU가 3개 있고 그 번호가 0, 1, 2 인 상황의 예제입니다.\n",
        "# 만약 GPU가 5개이고 사용 가능한 것이 0, 3, 4 라면 \"0,3,4\" 라고 적으면 됩니다.\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
        "\n",
        "# 현재 PC의 사용가능한 GPU 사용 갯수 확인\n",
        "torch.cuda.device_count()\n",
        "\n",
        "# 사용 가능한 device 갯수에 맞춰서 0번 부터 GPU 할당\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(list(map(str, list(range(torch.cuda.device_count())))))\n",
        "\n",
        "# 실제 사용할 GPU만 선택하려면 아래와 같이 입력하면 됩니다. (예시)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 4, 6\"\n",
        "\n",
        "# cudnn을 사용하도록 설정. GPU를 사용하고 있으면 기본값은 True 입니다.\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.enabled = True\n",
        "\n",
        "# inbuilt cudnn auto-tuner가 사용 중인 hardware에 가장 적합한 알고리즘을 선택하도록 허용합니다.\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "oht2RKYBs4ns",
        "outputId": "23d90431-c736-4d6e-e92a-0753aa297f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-5906d60c9041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 아래 코드의 \"0,1,2\"는 GPU가 3개 있고 그 번호가 0, 1, 2 인 상황의 예제입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 만약 GPU가 5개이고 사용 가능한 것이 0, 3, 4 라면 \"0,3,4\" 라고 적으면 됩니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0,1,2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 현재 PC의 사용가능한 GPU 사용 갯수 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU device의 사용 가능한 메모리를 코드 상에서 확인하려면 아래 함수를 사용합니다.\n",
        "# unit : byte\n",
        "torch.cuda.get_device_properties(\"cuda:0\").total_memory\n",
        "\n",
        "# unit : mega byte\n",
        "torch.cuda.get_device_properties(\"cuda:0\").total_memory // 1e6\n",
        "\n",
        "# unit : giga byte\n",
        "torch.cuda.get_device_properties(\"cuda:0\").total_memory // 1e9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHGM0nhetLdr",
        "outputId": "a6c3a6da-b4d8-40e7-849d-9be46b77d92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.0"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#멀티 GPU 사용 시 사용 시 아래 코드를 사용하여 전체 사용 가능한 GPU 메모리를 확인할 수 있습니다.\n",
        "gpu_ids = list(map(str, list(range(torch.cuda.device_count()))))\n",
        "total_gpu_memory = 0\n",
        "for gpu_id in gpu_ids:\n",
        "    total_gpu_memory += torch.cuda.get_device_properties(\"cuda:\" + gpu_id).total_memory"
      ],
      "metadata": {
        "id": "TaB4AgQQtTi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CUDA 할당 된 Tensor를 GPU에서 완전히 메모리 해제를 하려면 \n",
        "#① 변수를 제거하고 ② cache를 비워야 실제 메모리에서 해제\n",
        "\n",
        "A = torch.rand(1000000000).cuda()\n",
        "print(torch.cuda.memory_allocated())\n",
        "# 4000000000 \n",
        "print(torch.cuda.memory_reserved())\n",
        "# 4001366016\n",
        "\n",
        "del A\n",
        "print(torch.cuda.memory_allocated())\n",
        "# 0 \n",
        "print(torch.cuda.memory_reserved())\n",
        "# 4001366016\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_allocated())\n",
        "# 0\n",
        "print(torch.cuda.memory_reserved())\n",
        "# 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M32qpXEbuLpn",
        "outputId": "050d62c1-6921-43e1-c33d-5f17f24ef9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000001536\n",
            "4003463168\n",
            "1536\n",
            "4003463168\n",
            "1536\n",
            "2097152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATALOADER Setting"
      ],
      "metadata": {
        "id": "rBcS79oSxAJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://gaussian37.github.io/dl-pytorch-snippets/\n",
        "\n",
        "- pytorch를 이용하여 학습을 할 때, 데이터를 불러오는 방법으로 DataLoder(from torch.utils.data import DataLoader)를 사용\n",
        "- Dataloader의 num_workers는 CPU → GPU로 데이터를 로드할 때 사용하는 프로세스의 갯수를 뜻\n",
        "- __num_workers = 4 x num_GPU가 사용하기 좋았다라는 의견이 있었습니다. 예를 들어 GPU 2개를 사용하면 num_workers = 8을 사용__"
      ],
      "metadata": {
        "id": "_OWh651ivOsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch.utils.data.DataLoader()를 사용할 때, 옵션으로 pin_memory = True 라는 것이 있습니다. 이 옵션의 의미에 대하여 알아보도록 하겠습니다. (pin memory : 고정된 메모리)\n",
        "- 먼저 pin_memory = False가 기본값으로 사용됩니다. 이 옵션의 의미는 CPU → GPU로의 메모리 복사 시 오직 main process에서만 복사가 발생하도록 하는 synchronous 방법을 의미합니다. 하드웨어 자원이 많을 때, 궂이 하나의 프로세스에서만 작업하는 것은 비효율적\n",
        "- __GPU를 이용할 때에는 torch.utils.data.DataLodaer(pin_memory = True)를 사용__"
      ],
      "metadata": {
        "id": "JIzTrgVav4h2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- __GPU를 이용하여 학습할 때, 바로 앞의 dataloader의 pin_memory 사용과 더불어 data의 .cuda(non_blocking=True)는 일반적으로 반드시 사용하는 옵션__\n",
        "- 데이터 전송과 계산을 겹쳐서 (비동기식)으로 할 수 있으므로 연산 속도 향상에 도움을 줍니다."
      ],
      "metadata": {
        "id": "DcN7DBpIwYQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (images, target) in enumerate(train_loader):\n",
        "    # measure data loading time\n",
        "    data_time.update(time.time() - end)\n",
        "\n",
        "    if args.gpu is not None:\n",
        "        images = images.cuda(args.gpu, non_blocking=True)\n",
        "    if torch.cuda.is_available():\n",
        "        target = target.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "    # compute output\n",
        "    output = model(images)\n",
        "    loss = criterion(output, target)"
      ],
      "metadata": {
        "id": "364zZh-Tubsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## optimizer.zero_grad(), loss.backward(), optimizer.step()\n",
        "\n",
        "- optimizer.zero_grad() : 이전 step에서 각 layer 별로 계산된 gradient 값을 모두 0으로 초기화 시키는 작업입니다. 0으로 초기화 하지 않으면 이전 step의 결과에 현재 step의 gradient가 누적으로 합해져서 계산되어 집니다.\n",
        "- loss.backward() : 각 layer의 파라미터에 대하여 back-propagation을 통해 gradient를 계산합니다.\n",
        "- optimizer.step() : 각 layer의 파라미터와 같이 저장된 gradient 값을 이용하여 파라미터를 업데이트 합니다. 이 명령어를 통해 파라미터가 업데이트되어 모델의 성능이 개선됩니다."
      ],
      "metadata": {
        "id": "ij3dhlMvw-Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pytorch에서 학습 시, weight를 업데이트 하는 시점은 optimizer.step()이 실행되는 시점\n",
        "- optimizer.step()을 사용하는 순서를 확인해 보면 뉴럴네트워크의 출력값과 라벨 값을 loss 함수를 이용하여 계산을 하고 그 loss 함수의 .backward() 연산을 한 뒤에 optimizer.step()을 통해 weight를 업데이트\n",
        "- 보통 loss function은 다음과 같이 선언합니다"
      ],
      "metadata": {
        "id": "umP1_ZuQxaMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "out = model(input)\n",
        "loss = criterion(out, target)\n",
        "loss.backward()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "dZDZoeFKxNGQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "8286d9c7-e2b2-4a50-8233-5ee3745816e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-aaddc29df749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## batch size, iteration, epoch\n",
        "- 보통 학습을 할 때에는 GPU 메모리의 한계로 인하여 한번에 GPU를 통해 연산되는 데이터 양이 제한적입니다. 예를 들어 데이터가 총 100개가 있으면 20개씩 데이터를 분할하여 5번 나눠서 학습을 하곤 합니다. 이 때, 20개라는 데이터의 크기를 batch size라고 합니다. 그리고 5번 이라는 나눠서 학습하는 횟수를 iteration이라고 합니다. 따라서 batch size * iteration을 하면 현재 가지고 있는 데이터 전체를 대상으로 학습을 하게 됩니다. 전체 데이터를 학습한 단위를 epoch이라고 합니다. 10 epoch을 학습하였다는 뜻은 100개의 데이터를 10번 반복학습 하였다는 뜻입니다.\n",
        "-  한 epoch에서 각 iteration 마다 20개의 batch를 학습하면 총 5번의 gradient가 계산되어야 합니다. 이 때, pytorch에서는 기본적으로 이 gradient를 누적 하여 합하게 됩니다. 따라서 다음과 같은 2가지 전략을 세울 수 있습니다.\n",
        "1. iteration 마다 weight를\n",
        " update 하는 방법 : gradient가 누적되지 않게 iteration 시작 시 이전 iteration에서 계산된 gradient를 0으로 초기화합니다.\n",
        "2. epoch 마다 weight를 update 하는 방법 : 모든 iteration에서 계산된 gradient를 누적하여 한번에 weight update를 합니다. 따라서 epoch이 시작 시 계산된 gradient를 0으로 초기화 합니다.\n",
        "- 일반적으로 ① 방법인 iteration 마다 weight를 업데이트 하는 방법을 많이 사용하고 저 또한 이 방법을 사용하여 학습합니다.\n"
      ],
      "metadata": {
        "id": "LmuNWyTGyjVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs 만큼 반복 학습한다. 위 예시에서 10번 반복학습에 해당함.\n",
        "for epoch in range(epochs):\n",
        "    # 위 예시에서 batches는 총 5개의 batch를 가지고 있으며,\n",
        "    # 각 train_data는 20개의 데이터를 가지고 있음 20x5=100 batch_size=20, iter=5\n",
        "    for num_train, (train_data, target_data) in enumerate(batches):\n",
        "        # ★★★ gradient를 0으로 셋팅함 ★★★\n",
        "        optimizer.zero_grad()\n",
        "        out = nn_model(train_data)\n",
        "        loss = loss_function(out, target_data)\n",
        "        loss.backward()\n",
        "        loss_sum += loss.item()\n",
        "        # iteration 마다 계산된 gradient를 weight에 반영\n",
        "        optimizer.step()\n",
        "    loss_list.append(loss_sum / (num_train + 1))"
      ],
      "metadata": {
        "id": "_m3UenmIyofr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs 만큼 반복 학습한다. 위 예시에서 10번 반복학습에 해당함.\n",
        "for epoch in range(epochs):\n",
        "    # ★★★ gradient를 0으로 셋팅함 ★★★\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 위 예시에서 batches는 총 5개의 batch를 가지고 있으며,\n",
        "    # 각 train_data는 20개의 데이터를 가지고 있음\n",
        "    for num_train, (trarin_data, target_data) in enumerate(batches):\n",
        "        out = nn_model(trarin_data)\n",
        "        loss = loss_function(out, target_data)\n",
        "        loss.backward()\n",
        "        loss_sum += loss.item()\n",
        "        \n",
        "    # epoch 마다 계산된 gradient를 weight에 반영\n",
        "    optimizer.step()\n",
        "    loss_list.append(loss_sum / (num_train + 1))"
      ],
      "metadata": {
        "id": "nVBMWF-Z0a1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## validation의 Loss 계산 시 detach 사용 관련\n",
        "- 학습 중 일부 epoch을 진행한 다음에 CUDA error: out of memory 에러가 발생하는 경우가 있습니다.\n",
        "- 학습 단계에서 가장 기본적으로 Train 데이터 셋과 Validation 데이터 셋에 대하여 Loss를 구합니다.\n",
        "- Train 데이터 셋을 사용하는 경우 ① Loss를 구하고 ② Loss의 .backward()를 이용하여 backpropagation을 적용합니다.\n",
        "반면 Validation 데이터 셋을 사용하는 경우 Loss만 구하고 backpropagation은 적용하지 않습니다.\n",
        "- 이러한 차이점으로 인하여 의도치 않게 Pytorch를 사용할 떄, CUDA error: out of memory 문제가 발생하곤 합니다.\n",
        "- 이 경우 loss에 .detach() 함수를 사용하여 그래프의 히스토리를 의도적으로 끊는 방법을 사용하여 메모리 문제를 피할 수 있습니다."
      ],
      "metadata": {
        "id": "L_X83zPP9dHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch 사용 시, ① model → ② optimizer → ③ loss 순서로 연결이 되어 있습니다. \n",
        "#예를 들어 다음 코드와 같습니다.\n",
        "out = model(input)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(out, target)\n",
        "loss.backward()\n",
        "\n",
        "out = model(input)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(out, target).detach()\n",
        "#이 경우 loss의 그래프가 끊어졌기 떄문에 backward()를 사용할 수 없습니다. \n",
        "#따라서 이 경우는 backward()를 사용하지 않는 validation 데이터 셋 연산 시 \n",
        "#위 코드와 같이 loss의 .detach()를 사용할 수 있습니다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "CN-97k8u0mpP",
        "outputId": "bc0d93f7-d102-4bf8-f598-e69b9d5edb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-2d611e14e1b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'zero'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train 데이터 셋 : Train 시 loss.backward()를 사용하고 loss.backward() 시, loss의 그래프 히스토리가 초기화되므로 epoch이 진행 됨에 따라 그래프가 계속 누적되어 메모리 문제가 발생하지 않음\n",
        "- Validation(Test) 데이터 셋 : Validation(Test) 시 loss.backward()를 사용하지 않으므로 loss의 그래프 히스토리가 계속 누적되어 epoch이 진행됨에 따라 메모리 문제가 발생하게 됨. 따라서 loss.detach()를 이용하여 loss의 그래프가 누적되지 않도록 의도적으로 끊어주어 메모리 문제를 개선할 수 있음"
      ],
      "metadata": {
        "id": "4QAJviRVAXtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model.eval()와 torch.no_grad() 비교\n",
        "- model.eval() : .eval()모드를 사용하면 모델 내부의 모든 layer가 evaluation 모드가 됩니다. evaluation 모드에서는 batchnorm, dropout과 같은 기능들이 사용되지 않습니다.\n",
        "- torch.no_grad() : 어떤 Tensor가 .no_grad()로 지정이 되면 autograd 엔진에게 이 정보를 알려주고 학습에서 제외됩니다. 학습에서 제외되기 때문에 Backprop에 필요한 메모리 등을 절약할 수 있으므로 이 Tensor를 사용하여 계산 시 연산 속도가 빨라집니다. 하지만 Backprop을 할 수 없으므로 학습은 불가능 합니다.\n",
        "\n",
        "- model.eval()은 실제 inference를 하기 전에 model의 모든 layer를 evaluation 모드로 변경하기 위해 사용하면 됩니다. 특히 dropout과 batchnorm이 model에 포함되어 있다면 반드시 사용해야 합니다.\n",
        "- 반면 torch.no_grad()는 특정 레이어에서 backprop을 적용시키지 않기 위하여 사용됩니다. 따라서 학습에서 제외할 layer가 있다면 그 layer를 위해 사용하면 됩니다.\n"
      ],
      "metadata": {
        "id": "20l7vXIIArRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1],dtype=torch.float64 ,requires_grad=True)\n",
        "\n",
        "# with 구문을 이용하여 Tensor의 성분을 no_grad로 변경\n",
        "with torch.no_grad():\n",
        "  y = x * 2\n",
        "y.requires_grad\n",
        "# False\n",
        "\n",
        "# decorator를 이용하여 Tensor의 성분을 no_grad로 변경\n",
        "@torch.no_grad()\n",
        "def doubler(x):\n",
        "    return x * 2\n",
        "z = doubler(x)\n",
        "z.requires_grad\n",
        "# False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqKVh5770qiM",
        "outputId": "39c5df1e-c0ce-40cd-e4f4-2b34c71dee86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "drop = torch.nn.Dropout(p=0.3)\n",
        "x = torch.ones(1, 10)\n",
        "\n",
        "# Train mode (default after construction)\n",
        "drop.train()\n",
        "print(drop(x))\n",
        "# tensor([[1.4286, 1.4286, 0.0000, 1.4286, 0.0000, 1.4286, 1.4286, 0.0000, 1.4286, 1.4286]])\n",
        "\n",
        "# Eval mode\n",
        "drop.eval()\n",
        "print(drop(x))\n",
        "# tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntnCRbktDFmE",
        "outputId": "791dc024-2130-49cb-f300-b614a639c327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4286, 1.4286, 1.4286, 1.4286, 1.4286, 1.4286, 0.0000, 1.4286, 1.4286,\n",
            "         1.4286]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dropout 적용 시 Tensor 값 변경 메커니즘\n",
        "- Tensor의 Train 모드에서는 dropout이 적용된 Tensor는 값 일부가 0으로 바뀌게 됩니다.\n",
        "- 아래 예제를 보면 Dropout을 적용하기 이전의 값은 모두 1을 가지고 있습니다.\n",
        "- 반면 dropout이 적용되면 일부 값은 0을 가지고 0이 되지 않은 값은 기존의 값 1보다 더 커진것을 알 수 있습니다.\n",
        "- 이와 같이 값이 변경 되는 것은 처음에 Dropout을 선언할 때, 입력한 파라미터 p와 (torch.nn.Dropout(p)) 연관되어 있습니다.\n",
        "위 예제에서 p = 0.3이라는 뜻은 전체 값 중 0.3의 확률로 0이 된다는 것을 뜻합니다.\n",
        "- 이 때 0이 되지 않은 0.7에 해당하는 값은 (1/0.7) 만큼 scale이 됩니다. 따라서 (1/0.7 = 1.4286…)이 됩니다.\n",
        "- 정리하면 Dropout에 적용된 p 만큼의 비율로 Tensor의 값이 0이되고 0이되지 않은 값들은 기존값에 (1/(1-p)) 만큼 곱해져서 값이 커집니다."
      ],
      "metadata": {
        "id": "lRJMqb0tEST8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "drop = torch.nn.Dropout(p=0.3)\n",
        "x = torch.ones(1, 10)\n",
        "\n",
        "# Train mode (default after construction)\n",
        "drop.train()\n",
        "print(drop(x))\n",
        "# tensor([[1.4286, 1.4286, 0.0000, 1.4286, 0.0000, 1.4286, 1.4286, 0.0000, 1.4286, 1.4286]])\n",
        "\n",
        "# Eval mode\n",
        "drop.eval()\n",
        "print(drop(x))\n",
        "# tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnbsPi8ZELOj",
        "outputId": "59c18486-2deb-4448-8bdf-1e471b35c92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4286, 1.4286, 0.0000, 1.4286, 1.4286, 1.4286, 1.4286, 1.4286, 1.4286,\n",
            "         1.4286]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## opencv로 이미지를 읽어서 tensor로 변환\n",
        "- opencv와 같은 라이브러리로 이미지를 읽으면 (H, W, C)와 같은 형태로 읽게 되어 있으며 pytorch에서 다루는 tensor는 (Batch, Channel, Height, Width) 형태로 사용하게 됩니다. 그리고 학습 시 사용하는 tensor 값의 범위는 0 ~ 1로 스케일이 변경되도록 많이 사용합니다.\n",
        "- 아래 코드의 load_image를 사용하면 이미지를 opencv로 읽어서 BGR을 RGB로 바꾼 뒤, 원하는 사이즈로 resize까지 적용합니다.\n",
        "- 그리고 tensorify를 사용하면 (H, W, C) 형태의 numpy 데이터를 (B, C, H, W)의 tensor로 변경해 줍니다. 이 때 tensor의 크기는 (1, C, H, W)가 되며 값의 범위도 0 ~ 1 로 변경됩니다.\n"
      ],
      "metadata": {
        "id": "eE8cXmTfExwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "load_images = lambda path, h, w: cv2.resize(cv2.cvtColor(cv2.imread(path, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB), ((w, h)))\n",
        "#cv2.IMREAD_UNCHANGED 이미지파일을 alpha channel까지 포함하여 읽는다.\n",
        "tensorify = lambda x: torch.Tensor(x.transpose((2, 0, 1))).unsqueeze(0).float().div(255.0)\n",
        "#tensor의 크기는 (1, C, H, W)가 되며 값의 범위도 0 ~ 1 로 변경\n",
        "\n",
        "img_tensor = tensorify(load_images(\"img.png\", 400, 300))\n",
        "print(img_tensor.shape)\n",
        "# torch.Size([1, 3, 400, 300])"
      ],
      "metadata": {
        "id": "mTzPO1opEXVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.argmax(input, dim, keepdim)\n",
        "- input은 Tensor를 나타내고 dim은 몇번 째 축을 기준으로 argmax 연산을 할 지 결정합니다. 마지막으로 keepdim은 argmax 연산을 한 축을 생략할 지 그대로 둘 지에 대한 기준이 됩니다.\n"
      ],
      "metadata": {
        "id": "ygkTPIzaNzzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. input이 (channel, height, widht) 인 경우\n",
        "torch.argmax(input, dim = 0, keepdim = True)\n",
        "\n",
        "# 2. input이 (batch, channel, height, width) 인 경우\n",
        "torch.argmax(input, dim = 1, keepdim = True) "
      ],
      "metadata": {
        "id": "y6tdjI_TNLV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# ctrl + / , 전체주석\n",
        "# channel : 3, height : 4, width : 2로 가정합니다.\n",
        "# A = torch.randint(10, (3, 4, 2))\n",
        "print(A)\n",
        "\n",
        "# 0번째 축(channel) 기준 argmax w/o Keepdim\n",
        "print(torch.argmax(A, dim=0))\n",
        "print(torch.argmax(A, dim=0).shape)\n",
        "\n",
        "\n",
        "# 0번째 축(channel) 기준 argmax w/ Keepdim\n",
        "print(torch.argmax(A, dim=0, keepdim = True))\n",
        "print(torch.argmax(A, dim=0, keepdim = True).shape)\n",
        "\n",
        "\n",
        "# # 1번째 축(height) 기준 argmax w/o Keepdim\n",
        "# print(torch.argmax(A, dim=1))\n",
        "# print(torch.argmax(A, dim=1).shape)\n",
        "\n",
        "\n",
        "# # 1번째 축(height) 기준 argmax w/ Keepdim\n",
        "# print(torch.argmax(A, dim=1, keepdim = True))\n",
        "# print(torch.argmax(A, dim=1, keepdim = True).shape)\n",
        "\n",
        "\n",
        "# # 2번째 축(width) 기준 argmax w/o Keepdim\n",
        "# print(torch.argmax(A, dim=2))\n",
        "# print(torch.argmax(A, dim=2).shape)\n",
        "\n",
        "\n",
        "# # 2번째 축(width) 기준 argmax w/ Keepdim\n",
        "# print(torch.argmax(A, dim=2, keepdim=True))\n",
        "# print(torch.argmax(A, dim=2, keepdim=True).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFbf09BWNLQj",
        "outputId": "70dfac79-5e04-4115-e31e-b69fc160d9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[5, 4],\n",
            "         [4, 4],\n",
            "         [5, 7],\n",
            "         [7, 6]],\n",
            "\n",
            "        [[0, 4],\n",
            "         [7, 7],\n",
            "         [9, 4],\n",
            "         [8, 6]],\n",
            "\n",
            "        [[2, 8],\n",
            "         [4, 7],\n",
            "         [1, 7],\n",
            "         [6, 3]]])\n",
            "tensor([[0, 2],\n",
            "        [1, 1],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n",
            "torch.Size([4, 2])\n",
            "tensor([[[0, 2],\n",
            "         [1, 1],\n",
            "         [1, 0],\n",
            "         [1, 0]]])\n",
            "torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy → Tensor / Tensor → Numpy\n"
      ],
      "metadata": {
        "id": "SG-EvXc6ZyoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "A = np.random.rand(3, 100, 100)\n",
        "torch.from_numpy(A)\n",
        "type(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCsc0OvKRVjA",
        "outputId": "c447256d-a148-4537-bd53-9aabb88dee00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ① Tensor가 backprop 시 연산이 되지 않도록 .detach()를 하여 그래프에서 분리시킵니다.\n",
        "- ② 일반적으로 numpy는 CPU 기반의 연산을 사용합니다. 즉, GPU 연산을 사용하지 않으므로 .cpu()를 통해 CPU 모드로 변환합니다.\n",
        "- ③ 마지막으로 numpy()로 변환해 줍니다.\n",
        "- 이 과정을 통해 어떤 Tensor A가 있다면 A_np = A.detach().cpu().numpy()를 통해 numpy로 변환이 가능합니다. 이 때, 기본적으로 float32 타입으로 변환됩니다."
      ],
      "metadata": {
        "id": "5_vSUt9MaHzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor().numpy()\n",
        "torch.Tensor().cpu().data.numpy()\n",
        "torch.Tensor().cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "1LFohDOSZ86j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## block을 쌓기 위한 Module, Sequential, ModuleList, ModuleDict\n",
        "- Module : 여러 개의 작은 블록으로 구성된 큰 블록이 있을 때\n",
        "- Sequential : 레이어에서 작은 블록을 만들고 싶을 때\n",
        "- ModuleList : 일부 레이어 또는 빌딩 블록을 반복하면서 어떤 작업을 해야 할 때\n",
        "- ModuleDict : 모델의 일부 블록을 매개 변수화 해야하는 경우 (예 : activation 기능)"
      ],
      "metadata": {
        "id": "-CPtOOwpbz7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# nn.Module\n",
        "# nn.Sequential\n",
        "# nn.ModuleList\n",
        "# nn.ModuleDict"
      ],
      "metadata": {
        "id": "5eE4kgYjaYW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, in_c, n_classes): #input channel, n-class\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_c, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
        "        self.fc2 = nn.Linear(1024, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "0Mqj_OXtaYPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, in_c, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_c, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, n_classes)\n",
        "        )\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x) #conv_block1\n",
        "        x = self.conv_block2(x) #conv_block2 코드 중복\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        \n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "LuuWmqCQdv7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_f, out_f, *args, **kwargs):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
        "        nn.BatchNorm2d(out_f),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, in_c, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv_block1 = conv_block(in_c, 32, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.conv_block2 = conv_block(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, n_classes)\n",
        "        )\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        \n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "5oFmD5xtdv28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_f, out_f, *args, **kwargs):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
        "        nn.BatchNorm2d(out_f),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, in_c, n_classes):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(in_c, 32, kernel_size=3, padding=1),\n",
        "            conv_block(32, 64, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, n_classes)\n",
        "        )\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HkRYX6YOdv0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#??? zip(self.enc_sizes, self.enc_sizes[1:])\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, in_c, n_classes):\n",
        "        super().__init__()\n",
        "        self.enc_sizes = [in_c, 32, 64]\n",
        "        conv_blocks = [conv_block(in_f, out_f, kernel_size=3, padding=1) for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])]\n",
        "        self.encoder = nn.Sequential(*conv_blocks)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, n_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "UcsJO0Ecdvor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXxN_874fnJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}